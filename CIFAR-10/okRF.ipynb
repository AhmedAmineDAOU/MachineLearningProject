{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest  on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/cifar-10-python.tar.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3b9792a4d506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n\u001b[0;32m----> 9\u001b[0;31m                                         download=True, transform=transform)\n\u001b[0m\u001b[1;32m     10\u001b[0m trainloader = torch.utils.data.DataLoader(trainset, batch_size=50000,\n\u001b[1;32m     11\u001b[0m                                           shuffle=True, num_workers=2)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# extract file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/cifar-10-python.tar.gz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & printing shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[after reshaping]\n",
      "trainig   data shape  :  torch.Size([50000, 3072]) 50000 examples\n",
      "testing   data shape  :  torch.Size([10000, 3072]) 10000 examples\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "trainset, y_train = dataiter.next()\n",
    "testiter = iter(testloader)\n",
    "testset, y_test = testiter.next()\n",
    "\n",
    "ten = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "x_train = trainset.reshape((50000, 3072))\n",
    "y_train1 = list(y_train.flatten())\n",
    "x_test = testset.reshape((10000, 3072))\n",
    "y_test1 = list(y_test.flatten())\n",
    "\n",
    "print(\"[after reshaping]\")\n",
    "print(\"trainig   data shape  : \",x_train.shape ,x_train.shape[0], 'examples')\n",
    "print(\"testing   data shape  : \",x_test.shape,x_test.shape[0], 'examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "First data visualisation without any pre-processing on it.\n",
    "Printing 10 first images from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "figure1 = plt.figure(figsize=(15,5))\n",
    "for i in range(1,5):\n",
    "    single_img = np.array(x_train[i])\n",
    "    single_img_reshaped = np.transpose(np.reshape(single_img,(3, 32,32)), (1,2,0))\n",
    "    images = figure1.add_subplot(2, 5, i , xticks=[], yticks=[])\n",
    "    images.imshow(single_img_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF: Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn import ensemble\n",
    "n_samples=len(x_train)\n",
    "n_samples2=len(x_test)\n",
    "\n",
    "X=x_train.reshape(n_samples,-1)\n",
    "Y=y_train\n",
    "x=X.numpy()\n",
    "y=Y.numpy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "X2=x_test.reshape(n_samples2,-1)\n",
    "Y2=y_test\n",
    "xt=X2.numpy()\n",
    "yt=Y2.numpy()\n",
    "print(xt.shape)\n",
    "print(yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "sample_index=random.sample(range(len(x)),int(len(x)/5))\n",
    "valid_index=[i for i in range(len(x)) if i not in sample_index]\n",
    "print(len(sample_index))\n",
    "print(len(valid_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "sample_images=[x[i] for i in sample_index]\n",
    "valid_images=[x[i] for i in valid_index]\n",
    "print(len(sample_images))\n",
    "print(len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_target=[y[i] for i in sample_index]\n",
    "valid_target=[y[i] for i in valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features\n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# First create the base model to tune\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "# using 3 fold cross validation, \n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 3, refit='AUC', return_train_score=True, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(sample_images, sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimator found by grid search:\")\n",
    "print(rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree=[100,400,700,1000,1300,1600,2000]\n",
    "ascore=[]\n",
    "for n in n_tree:\n",
    "    classifier=ensemble.RandomForestClassifier(n_estimators=n,max_features=\"sqrt\")\n",
    "    classifier.fit(sample_images,sample_target)\n",
    "    ascore.append(classifier.score(valid_images,valid_target))\n",
    "print('Scores:',ascore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.title('Random Forest')\n",
    "plt.plot(n_tree, ascore, label='Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('num_trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=ensemble.RandomForestClassifier(n_estimators=2000,max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(sample_images,sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {}'.format(accuracy_score(yt, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
